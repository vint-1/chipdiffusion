{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../diffusion\")\n",
    "\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pickle\n",
    "import collections\n",
    "import re\n",
    "\n",
    "DEVICE=\"cuda:0\"\n",
    "\n",
    "def plot_set(data_set, nrows = 3, ncols = 6, scale_factor = 1.0):\n",
    "    fig, axes = plt.subplots(nrows, ncols)\n",
    "    fig.set_size_inches(scale_factor*ncols*2, scale_factor*nrows*2)\n",
    "    for i, (x, cond) in enumerate(data_set):\n",
    "        img = utils.visualize_placement(x, cond)\n",
    "        ax = axes[i//ncols][i%ncols] if nrows > 1 else axes[i%ncols]\n",
    "        ax.imshow(img)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_placement(x, cond, scale=1):\n",
    "    if len(cond.chip_size) == 4: # chip_size is [x_start, y_start, x_end, y_end]\n",
    "        chip_size = (cond.chip_size[2] - cond.chip_size[0], cond.chip_size[3] - cond.chip_size[1])\n",
    "        chip_offset = (cond.chip_size[0], cond.chip_size[1])\n",
    "    else:\n",
    "        chip_size = (cond.chip_size[0], cond.chip_size[1])\n",
    "        chip_offset = (0, 0)\n",
    "    chip_size = torch.tensor(chip_size, dtype = torch.float32).view(1, 2)\n",
    "    chip_offset = torch.tensor(chip_offset, dtype = torch.float32).view(1, 2)\n",
    "    x = (torch.tensor(x, dtype=torch.float32) - chip_offset)/scale\n",
    "    x = 2 * (x / chip_size) - 1\n",
    "    # use center of instance as coordinate point and reference for terminal\n",
    "    x = x + cond.x/2\n",
    "    return x\n",
    "\n",
    "def eval_set(data_set, eval_fn, **kwargs):\n",
    "    return [eval_fn(x, cond, normalized_hpwl=False, **kwargs)[1] for (x, cond) in data_set]\n",
    "\n",
    "def plot_and_eval_set(data_set, eval_fn, nrows = 3, ncols = 6, scale_factor = 1.0, title=None):\n",
    "    fig, axes = plt.subplots(nrows, ncols)\n",
    "    fig.set_size_inches(scale_factor*ncols*2, scale_factor*nrows*2 + 0.2)\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    for i, (x, cond) in enumerate(data_set):\n",
    "        img = utils.visualize_placement(x, cond)\n",
    "        ax = axes[i//ncols][i%ncols] if nrows > 1 else axes[i%ncols]\n",
    "        ax.imshow(img)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        metric = eval_fn(x, cond, normalized_hpwl=False)[1]\n",
    "        ax.set_title(f\"{metric:.0f}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_and_print_metrics(metrics, images, nrows = 3, ncols = 6, scale_factor = 1.0, title=None):\n",
    "    fig, axes = plt.subplots(nrows, ncols)\n",
    "    fig.set_size_inches(scale_factor*ncols*2, scale_factor*nrows*2 + 0.2)\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    for i, (metric, image) in enumerate(zip(metrics, images)):\n",
    "        ax = axes[i//ncols][i%ncols] if nrows > 1 else axes[i%ncols]\n",
    "        ax.imshow(image.T, origin=\"lower\", cmap=\"gray_r\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f\"{metric:.5g}\")\n",
    "    plt.show()\n",
    "\n",
    "def from_pl(base_path, cond, circuit_name=\"adaptec1\"):\n",
    "    # converts placements to a pl output, produces data as torch (V, 2) tensor\n",
    "    V = cond.num_nodes\n",
    "    data = torch.zeros((V,2), dtype=torch.float32)\n",
    "    fixed_mask = torch.zeros((V,), dtype=bool)\n",
    "    original_pl_file = os.path.join(base_path, circuit_name, f\"{circuit_name}_placed.pl\")\n",
    "    with open(original_pl_file, \"r\") as f:\n",
    "        i = 0\n",
    "        for line in f.readlines():\n",
    "            line_stripped = line.strip()\n",
    "            if not line_stripped.startswith(\"o\") and not line_stripped.startswith(\"p\"):\n",
    "                continue # not relevant to placement\n",
    "            else:\n",
    "                line_split = line_stripped.split()\n",
    "                obj_name = line_split[0]\n",
    "                obj_index = cond.name_index_mapping[obj_name]\n",
    "                data[obj_index, 0] = float(line_split[1]) \n",
    "                data[obj_index, 1] = float(line_split[2])\n",
    "                if len(line_split) > 5:\n",
    "                    if \"/FIXED\" in line_stripped:\n",
    "                        fixed_mask[obj_index] = True\n",
    "                    else:\n",
    "                        fixed_mask[obj_index] = False\n",
    "                else:\n",
    "                    if \"/FIXED\" in line_stripped: # unexpected\n",
    "                        import ipdb; ipdb.set_trace()\n",
    "                    fixed_mask[obj_index] = False\n",
    "                i += 1\n",
    "    data = data / 1000 # TRICK FOR ISPD\n",
    "    return data, fixed_mask\n",
    "\n",
    "def load_ispd_placements(base_dir, graph_dataset):\n",
    "    # Generates dataset of (x, cond) using placements from base_dir and cond from graph_dataset\n",
    "    ispd_mapping = [f\"adaptec{i+1}\" for i in range(4)] + [f\"bigblue{i+1}\" for i in range(4)] # maps file_idx to placement name\n",
    "    out_set = []\n",
    "    for _, cond in graph_dataset:\n",
    "        circuit_name = ispd_mapping[cond.file_idx]\n",
    "        load_path = os.path.join(base_dir, circuit_name, f\"{circuit_name}_placed.pl\")\n",
    "        if not os.path.exists(load_path):\n",
    "            print(f\"skipping {circuit_name}, {load_path} not found\")\n",
    "            continue\n",
    "        placement, fixed_mask = from_pl(base_dir, cond=cond, circuit_name=circuit_name)\n",
    "        cond[\"fixed_mask\"] = fixed_mask\n",
    "        placement = preprocess_placement(placement, cond)\n",
    "        out_set.append((placement, cond))\n",
    "    return out_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISPD_CHIP_SIZES = {\n",
    "    0: [0.459, 0.459, 0.459 + 10692/1000, 0.459 + 12*890/1000], # adaptec1\n",
    "    1: [0.609, 0.616, 0.609 + 14054/1000, 0.616 + 12*1170/1000],\n",
    "    2: [0.036, 0.058, 0.036 + 23190/1000, 23386/1000],\n",
    "    3: [0.036, 0.058, 0.036 + 23190/1000, 23386/1000],\n",
    "    4: [0.459, 0.459, 0.459 + 10692/1000, 11139/1000], # bigblue1 \n",
    "    5: [0.036, 0.076, 0.036 + 18690/1000, 18868/1000],\n",
    "    6: [0.036, 0.076, 0.036 + 27690/1000, 27868/1000],\n",
    "    7: [0.036, 0.058, 0.036 + 32190/1000, 32386/1000],\n",
    "}\n",
    "\n",
    "class Pin():\n",
    "    def __init__(self, id, obj_name, offset):\n",
    "        self.obj_name = obj_name\n",
    "        self.id = id\n",
    "        self.offset = offset\n",
    "    def __str__(self):\n",
    "        return f\"Pin(id:{self.id}, obj:{self.obj_name}, {self.offset})\"\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "def flip_stack(data):\n",
    "    \"\"\"\n",
    "    data is tensor (B, N, ...)\n",
    "    flips along N axis, then appends along B axis\n",
    "    Output is shaped (2B, N, ...)\n",
    "    \"\"\"\n",
    "    return torch.concatenate((data, torch.flip(data, dims=(1,))), dim=0)\n",
    "\n",
    "def parse_bookshelf(nodes_path, nets_path, pl_path, verbose=False, warn=False):\n",
    "    \"\"\"\n",
    "    Parses bookshelf circuit and placement and generates (x, cond) python objects\n",
    "\n",
    "    Returns:\n",
    "    - x: (V, 2) tensor with placement of objects (measured to bottom left) in non-normalized units\n",
    "    - cond: torch_geometric Data object containing the following keys:\n",
    "        - x: (V, 2) tensor containing sizes of objects\n",
    "        - is_ports: (V,) bool tensor\n",
    "        - is_macros: (V,) bool tensor\n",
    "        - edge_index: (2, E) int64 tensor\n",
    "        - edge_attr: (E, 4) tensor with pin offsets for start and end pins, measured from bottom left of object\n",
    "        - edge_pin_id: (E, 2) locally unique pin id (each pin has id unique among pins on the same object)\n",
    "        - name_index_mapping: {str : int} maps object names to index in tensors\n",
    "        NOTE: chip_size needs to be specified externally\n",
    "    \"\"\"\n",
    "\n",
    "    SCALING_UNITS = 1000\n",
    "    print_fn = print if verbose else lambda x: 0\n",
    "    warn_fn = print if warn else lambda x: 0\n",
    "\n",
    "    # Ingest Placement file\n",
    "    with open(pl_path, 'r') as pl_file:\n",
    "        pl_file_data = pl_file.readlines()\n",
    "    placement_line_pattern = re.compile(r\"^\\s*(\\S+)\\s+(\\d+(?:\\.\\d*)?)\\s+(\\d+(?:\\.\\d+)?)\\s*:\\s*(F?N|S|E|W)\\s*(/FIXED)?\\s*$\")\n",
    "    placement_dict = {\"obj_names\": [], \"positions\": [], \"is_fixed\": []}\n",
    "    for pl_line in pl_file_data:\n",
    "        match = re.match(placement_line_pattern, pl_line)\n",
    "        if match: # valid placement line\n",
    "            placement_dict[\"obj_names\"].append(match[1])\n",
    "            placement_dict[\"positions\"].append((float(match[2]), float(match[3])))\n",
    "            assert match[4] == \"N\", \"non-North orientations not supported\"\n",
    "            placement_dict[\"is_fixed\"].append(match[5] is not None) # unused for ISPD\n",
    "    print_fn(\"num objects:\", len(placement_dict[\"positions\"]))\n",
    "\n",
    "    # Ingest Nodes file\n",
    "    with open(nodes_path, 'r') as nodes_file:\n",
    "        nodes_file_data = nodes_file.readlines()\n",
    "    node_line_pattern = re.compile(r\"^\\s*(\\S+)\\s+(\\d+(?:\\.\\d+)?)\\s+(\\d+(?:\\.\\d*)?)\\s+(terminal)?$\")\n",
    "    node_size_dict = {} # name: size\n",
    "    node_macro_dict = {} # name: is_macro\n",
    "    for node_line in nodes_file_data:\n",
    "        match = re.match(node_line_pattern, node_line)\n",
    "        if match: # valid node data line\n",
    "            node_name = match[1]\n",
    "            assert node_name not in node_size_dict, \"duplicate node names detected\"\n",
    "            \n",
    "            node_size_dict[node_name] = (float(match[2]), float(match[3]))\n",
    "            node_macro_dict[node_name] = (match[4] is not None)\n",
    "    print_fn(\"num unique objects:\", len(node_size_dict))\n",
    "    print_fn(\"num macros:\", sum(node_macro_dict.values()))\n",
    "\n",
    "    # Ingest Nets file\n",
    "    with open(nets_path, 'r') as nets_file:\n",
    "        nets_file_data = nets_file.readlines()\n",
    "    \n",
    "    # header for each net\n",
    "    net_header_pattern = re.compile(r\"^\\s*NetDegree\\s*:\\s*(\\d+)\\s+(\\S+)\\s*$\") \n",
    "    # pin data in a net\n",
    "    net_line_pattern = re.compile(r\"^\\s*(\\S+)\\s+(I|O)\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s+(-?\\d+(?:\\.\\d+)?)\\s*$\")\n",
    "    \n",
    "    nets_started = False\n",
    "    line_num = 0\n",
    "    nets = []\n",
    "    one_deg_nets = 0\n",
    "    while line_num < len(nets_file_data):\n",
    "        nets_line = nets_file_data[line_num]\n",
    "        header_match = re.match(net_header_pattern, nets_line)\n",
    "        line_num += 1\n",
    "        if header_match: # start looking for nets\n",
    "            net_degree = int(header_match[1])\n",
    "            if net_degree < 2:\n",
    "                one_deg_nets += 1\n",
    "                line_num += net_degree\n",
    "                continue\n",
    "            net_name = header_match[2]\n",
    "            current_net = {\"inputs\": []}\n",
    "            for i in range(net_degree):\n",
    "                net_line_match = re.match(net_line_pattern, nets_file_data[line_num])\n",
    "                line_num += 1\n",
    "                assert net_line_match is not None, f\"{net_name} should have {net_degree} pins but found {i}\"\n",
    "                new_pin = Pin(\n",
    "                    id = line_num,\n",
    "                    obj_name = net_line_match[1],\n",
    "                    offset = (float(net_line_match[3]), float(net_line_match[4])),\n",
    "                    )\n",
    "                if net_line_match[2] == \"I\":\n",
    "                    current_net[\"inputs\"].append(new_pin)\n",
    "                else: # this is the source\n",
    "                    if \"output\" not in current_net: \n",
    "                        current_net[\"output\"] = new_pin\n",
    "                    else:\n",
    "                        warn_fn(f\"WARNING: multiple output pins detected in net {net_name}, using first output pin...\")\n",
    "                        current_net[\"inputs\"].append(new_pin)\n",
    "            if \"output\" not in current_net: \n",
    "                warn_fn(f\"WARNING: no output pins detected in {net_name}, using last pin...\")\n",
    "                current_net[\"output\"] = current_net[\"inputs\"].pop()\n",
    "            nets.append(current_net)\n",
    "        else:\n",
    "            assert not nets_started, f\"Expected contiguous block of nets, found {nets_line}, or previous net has more pins than header specifies.\"\n",
    "    print_fn(\"nets and pins after removing one-deg nets\", len(nets), sum([len(n[\"inputs\"])+1 for n in nets]))\n",
    "    print_fn(\"original nets and pins\", one_deg_nets+len(nets), one_deg_nets+sum([len(n[\"inputs\"])+1 for n in nets]))\n",
    "\n",
    "    # Generate per-node outputs\n",
    "    x = torch.tensor(placement_dict[\"positions\"]) # (V, 2)\n",
    "    is_macros = []\n",
    "    cond_x = []\n",
    "    name_index_mapping = {} # used to get object index from object_name\n",
    "    for obj_idx, obj_name in enumerate(placement_dict[\"obj_names\"]): # preserve object order\n",
    "        is_macros.append(node_macro_dict[obj_name])\n",
    "        cond_x.append(node_size_dict[obj_name])\n",
    "        name_index_mapping[obj_name] = obj_idx\n",
    "    is_macros = torch.tensor(is_macros) # (V,) bool\n",
    "    is_ports = torch.zeros_like(is_macros) # for ispd, no ports\n",
    "    cond_x = torch.tensor(cond_x) # (V, 2)\n",
    "    # Generate per-edge outputs\n",
    "    edge_indices = []\n",
    "    edge_attrs = []\n",
    "    edge_pin_ids = []\n",
    "    for net in nets:\n",
    "        net_source_pin = net[\"output\"]\n",
    "        for sink_pin in net[\"inputs\"]:\n",
    "            edge_indices.append(\n",
    "                (name_index_mapping[net_source_pin.obj_name], name_index_mapping[sink_pin.obj_name])\n",
    "            )\n",
    "            edge_attrs.append((*net_source_pin.offset, *sink_pin.offset))\n",
    "            edge_pin_ids.append((net_source_pin.id, sink_pin.id))\n",
    "    edge_index_unique = torch.tensor(edge_indices, dtype=torch.int64) # (E_u, 2)\n",
    "    edge_attr_unique = torch.tensor(edge_attrs) # (E_u, 4)\n",
    "    edge_pin_id_unique = torch.tensor(edge_pin_ids, dtype=torch.int64) # (E_u, 2)\n",
    "\n",
    "    # edge attribute should be measured wrt. bottom left\n",
    "    u_shape = cond_x[edge_index_unique[:,0]]\n",
    "    v_shape = cond_x[edge_index_unique[:,1]]\n",
    "    edge_attr_unique[:,:2] = edge_attr_unique[:,:2] + u_shape/2\n",
    "    edge_attr_unique[:,2:4] = edge_attr_unique[:,2:4] + v_shape/2\n",
    "    \n",
    "    E_u, _ = edge_index_unique.shape\n",
    "    edge_index = flip_stack(edge_index_unique).T\n",
    "    edge_attr = flip_stack(edge_attr_unique.view(E_u, 2, 2)).view(E_u*2, 4)\n",
    "    edge_pin_id = flip_stack(edge_pin_id_unique)\n",
    "\n",
    "    cond = Data(\n",
    "        x = cond_x/SCALING_UNITS,\n",
    "        edge_index = edge_index,\n",
    "        edge_attr = edge_attr/SCALING_UNITS,\n",
    "        edge_pin_id = edge_pin_id,\n",
    "        is_ports = is_ports,\n",
    "        is_macros = is_macros,\n",
    "        name_index_mapping = name_index_mapping,\n",
    "    )\n",
    "    return x/SCALING_UNITS, cond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Simple Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num objects: 3\n",
      "num unique objects: 3\n",
      "num macros: 2\n",
      "nets and pins after removing one-deg nets 3 8\n",
      "original nets and pins 3 8\n",
      "1 2\n",
      "torch.Size([3, 2]) Data(x=[3, 2], edge_index=[2, 10], edge_attr=[10, 4], edge_pin_id=[10, 2], is_ports=[3], is_macros=[3], chip_size=[4])\n",
      "HPWL 0.27299997210502625\n",
      "Macro HPWL 0.08500000089406967\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark_name = \"simple\"\n",
    "circuit_name = \"simple1\"\n",
    "nodes_path = f\"../benchmarks/{benchmark_name}/{circuit_name}/{circuit_name}.nodes\"\n",
    "nets_path = f\"../benchmarks/{benchmark_name}/{circuit_name}/{circuit_name}.nets\"\n",
    "pl_path = f\"../benchmarks/{benchmark_name}/{circuit_name}/{circuit_name}.pl\"\n",
    "\n",
    "x, cond = parse_bookshelf(nodes_path, nets_path, pl_path, verbose=True)\n",
    "cond[\"chip_size\"] = [0, 0, 0.1, 0.1]\n",
    "\n",
    "x, cond = utils.preprocess_graph(x, cond, chip_size=(0.1, 0.1))\n",
    "\n",
    "print(x.shape, cond)\n",
    "image1 = utils.visualize_placement(x, cond, plot_pins=True, plot_edges=True, img_size=(1024, 1024))\n",
    "utils.debug_plot_img(image1, name=f\"img_{circuit_name}\")\n",
    "\n",
    "print(\"HPWL\", utils.hpwl_fast(x, cond, normalized_hpwl=False)[1])\n",
    "print(\"Macro HPWL\", utils.macro_hpwl(x, cond, normalized_hpwl=False)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting ISPD Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERTING adaptec1...\n",
      "num objects: 211447\n",
      "num unique objects: 211447\n",
      "num macros: 543\n",
      "nets and pins after removing one-deg nets 219794 942705\n",
      "original nets and pins 221142 944053\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph0.pickle and placement to ../datasets/graph/ispd2005-s0/output0.pickle\n",
      "CONVERTING adaptec2...\n",
      "num objects: 255023\n",
      "num unique objects: 255023\n",
      "num macros: 566\n",
      "nets and pins after removing one-deg nets 260159 1063632\n",
      "original nets and pins 266009 1069482\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph1.pickle and placement to ../datasets/graph/ispd2005-s0/output1.pickle\n",
      "CONVERTING adaptec3...\n",
      "num objects: 451650\n",
      "num unique objects: 451650\n",
      "num macros: 723\n",
      "nets and pins after removing one-deg nets 466295 1874576\n",
      "original nets and pins 466758 1875039\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph2.pickle and placement to ../datasets/graph/ispd2005-s0/output2.pickle\n",
      "CONVERTING adaptec4...\n",
      "num objects: 496045\n",
      "num unique objects: 496045\n",
      "num macros: 1329\n",
      "nets and pins after removing one-deg nets 515304 1911773\n",
      "original nets and pins 515951 1912420\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph3.pickle and placement to ../datasets/graph/ispd2005-s0/output3.pickle\n",
      "CONVERTING bigblue1...\n",
      "num objects: 278164\n",
      "num unique objects: 278164\n",
      "num macros: 560\n",
      "nets and pins after removing one-deg nets 282974 1143186\n",
      "original nets and pins 284479 1144691\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph4.pickle and placement to ../datasets/graph/ispd2005-s0/output4.pickle\n",
      "CONVERTING bigblue2...\n",
      "num objects: 557866\n",
      "num unique objects: 557866\n",
      "num macros: 23084\n",
      "nets and pins after removing one-deg nets 576816 2121863\n",
      "original nets and pins 577235 2122282\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph5.pickle and placement to ../datasets/graph/ispd2005-s0/output5.pickle\n",
      "CONVERTING bigblue3...\n",
      "num objects: 1096812\n",
      "num unique objects: 1096812\n",
      "num macros: 1298\n",
      "nets and pins after removing one-deg nets 1122340 3832388\n",
      "original nets and pins 1123170 3833218\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph6.pickle and placement to ../datasets/graph/ispd2005-s0/output6.pickle\n",
      "CONVERTING bigblue4...\n",
      "num objects: 2177353\n",
      "num unique objects: 2177353\n",
      "num macros: 8170\n",
      "nets and pins after removing one-deg nets 2228903 8899095\n",
      "original nets and pins 2229886 8900078\n",
      "saved graph to ../datasets/graph/ispd2005-s0/graph7.pickle and placement to ../datasets/graph/ispd2005-s0/output7.pickle\n"
     ]
    }
   ],
   "source": [
    "ispd_names = [f\"adaptec{i+1}\" for i in range(4)] + [f\"bigblue{i+1}\" for i in range(4)]\n",
    "benchmark_path = \"../benchmarks/ispd2005/\"\n",
    "\n",
    "output_dir = \"../datasets/graph/ispd2005-s0\" # s for self-converted\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, name in enumerate(ispd_names):\n",
    "    print(f\"CONVERTING {name}...\")\n",
    "    nodes_path = os.path.join(benchmark_path, name, f\"{name}.nodes\")\n",
    "    nets_path = os.path.join(benchmark_path, name, f\"{name}.nets\")\n",
    "    pl_path = os.path.join(benchmark_path, name, f\"{name}.pl\")\n",
    "    x, cond = parse_bookshelf(nodes_path, nets_path, pl_path, verbose=True, warn=False)\n",
    "    cond.chip_size = ISPD_CHIP_SIZES[idx]\n",
    "    \n",
    "    cond_path = os.path.join(output_dir, f\"graph{idx}.pickle\")\n",
    "    x_path = os.path.join(output_dir, f\"output{idx}.pickle\")\n",
    "    \n",
    "    with open(cond_path, 'wb') as f:\n",
    "        pickle.dump(cond, f)\n",
    "    with open(x_path, 'wb') as f:\n",
    "        pickle.dump(x, f)\n",
    "    print(f\"saved graph to {cond_path} and placement to {x_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set and val set sizes:  0 8\n",
      "# objects: [211447, 255023, 451650, 496045, 278164, 557866, 1096812, 2177353]\n",
      "# objects in placement: [211447, 255023, 451650, 496045, 278164, 557866, 1096812, 2177353]\n",
      "# edges: [1445822, 1606946, 2816562, 2792938, 1720424, 3090094, 5420096, 13340384]\n",
      "# macros: [543, 566, 723, 1329, 560, 23084, 1298, 8170]\n",
      "# ports: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "# fixed in pl: [543, 566, 723, 1329, 560, 23084, 1298, 8170]\n",
      "mask overlap: [543, 566, 723, 1329, 560, 23084, 1298, 8170]\n"
     ]
    }
   ],
   "source": [
    "task = \"ispd2005-s0\"\n",
    "placement_name = \"chipformer_validation\"\n",
    "# placement_name = None\n",
    "placement_dir = f\"placements/{placement_name}/ispd2005\" if placement_name is not None else None\n",
    "train_set, val_set = utils.load_graph_data_with_config(\n",
    "    task, \n",
    "    train_data_limit = None, \n",
    "    val_data_limit = None,\n",
    "    )\n",
    "\n",
    "print(\"Train set and val set sizes: \", len(train_set), len(val_set))\n",
    "\n",
    "if placement_dir is None:\n",
    "    placed_set = val_set\n",
    "else:\n",
    "    placed_set = load_ispd_placements(placement_dir, val_set)\n",
    "placed_set = [(x.to(device=DEVICE), cond.to(device=DEVICE)) for x, cond in placed_set]\n",
    "mask_overlap = [(cond.fixed_mask & cond.is_macros).sum().cpu().item() for (_, cond) in placed_set]\n",
    "# placed_set = [utils.remove_non_macros(x, cond) for x, cond in placed_set] # This step is not strictly necessary, just speeds up plotting\n",
    "\n",
    "num_objects = [cond.num_nodes for (x, cond) in placed_set]\n",
    "num_placement_objects = [x.shape[0] for (x, cond) in placed_set]\n",
    "num_edges = [cond.num_edges for (x, cond) in placed_set]\n",
    "num_macros = [cond.is_macros.sum().cpu().item() for (x, cond) in placed_set]\n",
    "num_ports = [cond.is_ports.sum().cpu().item() for (x, cond) in placed_set]\n",
    "num_fixed_in_pl = [cond.fixed_mask.sum().cpu().item() for (x, cond) in placed_set] if placement_dir is not None else None\n",
    "print(\"# objects:\", num_objects)\n",
    "print(\"# objects in placement:\", num_placement_objects)\n",
    "print(\"# edges:\", num_edges)\n",
    "print(\"# macros:\", num_macros)\n",
    "print(\"# ports:\", num_ports)\n",
    "print(\"# fixed in pl:\", num_fixed_in_pl)\n",
    "print(\"mask overlap:\", mask_overlap)\n",
    "# print(placed_set[0][1])\n",
    "\n",
    "# plot_set(placed_set, nrows=1, ncols=2, scale_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ispd2005-s0 chipformer_validation\n",
      "Macro HPWL: [1017.4408569335938, 6492.77587890625, 7645.39013671875, 6741.654296875, 335.343505859375, 20402.7265625, 8278.671875, 134936.65625]\n",
      "HPWL: [106464.1953125, 109030.3125, 415542.3125, 462201.5625, 76343.6015625, 635635.5, 602586.125, 1939978.0]\n"
     ]
    }
   ],
   "source": [
    "print(task, placement_name)\n",
    "full_hpwl = eval_set(placed_set, eval_fn=utils.hpwl_fast)\n",
    "hpwl_results = eval_set(placed_set, eval_fn=utils.macro_hpwl)\n",
    "print(\"Macro HPWL:\", hpwl_results)\n",
    "print(\"HPWL:\", full_hpwl)\n",
    "\n",
    "# for i in range(2):\n",
    "#     image1 = utils.visualize_placement(*placed_set[i], plot_pins=True, img_size=(2048, 2048))\n",
    "#     utils.debug_plot_img(image1, name=f\"img{i}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
